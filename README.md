We propose a dual-stream architecture that fuses self-supervised learned representations (Mel-Spectrograms) with physiologically grounded source-filter features (Pitch, LPC). To address the 'black box' nature of deep learning, we implement a hybrid fusion strategy: a Dual-Stream Transformer captures temporal dependencies, while a Gradient Boosting Machine captures global statistical anomalies. By training on a class-balanced curriculum, our method achieves 79% accuracy on the test set, significantly outperforming single-stream baselines. Crucially, we provide explainability via attention heatmaps (identifying temporal biomarkers) and feature importance rankings (identifying key spectral attributes).
